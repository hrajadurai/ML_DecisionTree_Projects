{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80c8883c-a843-4aaf-b097-fbee3d516b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt,style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24d03455-08f1-4491-94ed-f5773ac2e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"petrol_consumption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d7ff411-dee5-4c18-bd66-b180b4e4f8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48 entries, 0 to 47\n",
      "Data columns (total 5 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Petrol_tax                    48 non-null     float64\n",
      " 1   Average_income                48 non-null     int64  \n",
      " 2   Paved_Highways                48 non-null     int64  \n",
      " 3   Population_Driver_licence(%)  48 non-null     float64\n",
      " 4   Petrol_Consumption            48 non-null     int64  \n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 2.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset.head()\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "285116e7-d684-4a8c-bdc3-f0515690f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "\n",
    "#For demonstration, lets assume \"Petrol_Consumption\" has been converted to a categorical target variable\n",
    "y=np.where(dataset['Petrol_Consumption'] > dataset['Petrol_Consumption'].median(),1,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f42a47c-4bd4-4ceb-ab76-49a93489357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4b9ba6-354a-4ba3-a3df-5f0be41d4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(oob_score=True, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(oob_score=True, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=100,random_state=0,oob_score=True)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d03d8ff-7880-4935-b71c-e5b88268b523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "Train Precision: 1.0\n",
      "Train Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "print('Train Accuracy:', metrics.accuracy_score(y_train, y_pred_train))\n",
    "print('Train Precision:', metrics.precision_score(y_train, y_pred_train))\n",
    "print('Train Recall:', metrics.recall_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db82e4c3-5f57-4724-a95c-344ba28643ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.50</td>\n",
       "      <td>5126</td>\n",
       "      <td>14186</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3333</td>\n",
       "      <td>6594</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3357</td>\n",
       "      <td>4121</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3846</td>\n",
       "      <td>9061</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.00</td>\n",
       "      <td>5002</td>\n",
       "      <td>9794</td>\n",
       "      <td>0.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4296</td>\n",
       "      <td>4083</td>\n",
       "      <td>0.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4716</td>\n",
       "      <td>5915</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4318</td>\n",
       "      <td>10340</td>\n",
       "      <td>0.586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4188</td>\n",
       "      <td>5975</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4897</td>\n",
       "      <td>2449</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4206</td>\n",
       "      <td>8508</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3656</td>\n",
       "      <td>3985</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4300</td>\n",
       "      <td>3635</td>\n",
       "      <td>0.603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4447</td>\n",
       "      <td>8577</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4207</td>\n",
       "      <td>6580</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3721</td>\n",
       "      <td>4746</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.00</td>\n",
       "      <td>5342</td>\n",
       "      <td>1333</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3718</td>\n",
       "      <td>4725</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.58</td>\n",
       "      <td>3802</td>\n",
       "      <td>7834</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4332</td>\n",
       "      <td>8159</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.50</td>\n",
       "      <td>3635</td>\n",
       "      <td>3274</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3745</td>\n",
       "      <td>2611</td>\n",
       "      <td>0.508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4574</td>\n",
       "      <td>2619</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5319</td>\n",
       "      <td>11868</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4258</td>\n",
       "      <td>4686</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.00</td>\n",
       "      <td>4045</td>\n",
       "      <td>17782</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4983</td>\n",
       "      <td>602</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4341</td>\n",
       "      <td>6010</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4512</td>\n",
       "      <td>8507</td>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4345</td>\n",
       "      <td>3905</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4476</td>\n",
       "      <td>3942</td>\n",
       "      <td>0.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.50</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5215</td>\n",
       "      <td>2302</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)\n",
       "11        7.50            5126           14186                         0.525\n",
       "31        7.00            3333            6594                         0.513\n",
       "33        7.50            3357            4121                         0.547\n",
       "27        7.50            3846            9061                         0.579\n",
       "47        7.00            5002            9794                         0.593\n",
       "2         9.00            3865            1586                         0.580\n",
       "46        7.00            4296            4083                         0.623\n",
       "18        7.00            4716            5915                         0.724\n",
       "15        7.00            4318           10340                         0.586\n",
       "28        8.00            4188            5975                         0.563\n",
       "22        9.00            4897            2449                         0.511\n",
       "16        7.00            4206            8508                         0.572\n",
       "41        7.00            3656            3985                         0.563\n",
       "20        7.00            4593            7834                         0.663\n",
       "42        7.00            4300            3635                         0.603\n",
       "8         8.00            4447            8577                         0.529\n",
       "13        7.00            4207            6580                         0.545\n",
       "25        9.00            3721            4746                         0.544\n",
       "5        10.00            5342            1333                         0.571\n",
       "17        7.00            3718            4725                         0.540\n",
       "35        6.58            3802            7834                         0.629\n",
       "14        7.00            4332            8159                         0.608\n",
       "38        8.50            3635            3274                         0.663\n",
       "1         9.00            4092            1250                         0.572\n",
       "12        7.00            4817            6930                         0.574\n",
       "43        7.00            3745            2611                         0.508\n",
       "24        8.50            4574            2619                         0.551\n",
       "6         8.00            5319           11868                         0.451\n",
       "23        9.00            4258            4686                         0.517\n",
       "36        5.00            4045           17782                         0.566\n",
       "21        8.00            4983             602                         0.602\n",
       "19        8.50            4341            6010                         0.677\n",
       "9         7.00            4512            8507                         0.552\n",
       "39        7.00            4345            3905                         0.672\n",
       "45        9.00            4476            3942                         0.571\n",
       "3         7.50            4870            2351                         0.529\n",
       "0         9.00            3571            1976                         0.525\n",
       "44        6.00            5215            2302                         0.672"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5416017d-a72d-409e-a086-202ccf6ddb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22527314, 0.26766953, 0.16359547, 0.34346185])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "121c64df-1a03-4410-a0a7-049dffba3580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Name</th>\n",
       "      <th>Importance Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Petrol_tax</td>\n",
       "      <td>0.268980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average_income</td>\n",
       "      <td>0.273738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paved_Highways</td>\n",
       "      <td>0.112864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Population_Driver_licence(%)</td>\n",
       "      <td>0.344418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Feature Name  Importance Score\n",
       "0                    Petrol_tax          0.268980\n",
       "1                Average_income          0.273738\n",
       "2                Paved_Highways          0.112864\n",
       "3  Population_Driver_licence(%)          0.344418"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Feature Name':dataset.iloc[:,:-1].columns,'Importance Score':classifier.feature_importances_})\n",
    "#pd.DataFrame({'Feature Name':dataset[:,:-1].columns,'Importance Score':classifier.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3796242-1181-4bcb-83f8-c5f6fd165054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.oob_score # Out of Bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0656bc81-d8e1-417d-ac45-20326e418d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631578947368421"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90ecbb9-0b7f-4f28-9489-f2aa6cadeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model is overfitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16399188-3668-4587-b375-defa4642af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9736842105263158\n",
      "Train Precision: 0.9473684210526315\n",
      "Train Recall: 1.0\n",
      "Train Accuracy: 0.8\n",
      "Train Precision: 1.0\n",
      "Train Recall: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100,random_state=0,oob_score=True,min_samples_split=12)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred_train = classifier.predict(X_train)\n",
    "print('Train Accuracy:', metrics.accuracy_score(y_train, y_pred_train))\n",
    "print('Train Precision:', metrics.precision_score(y_train, y_pred_train))\n",
    "print('Train Recall:', metrics.recall_score(y_train, y_pred_train))\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print('Train Accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "print('Train Precision:', metrics.precision_score(y_test, y_pred))\n",
    "print('Train Recall:', metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44a6f3b1-53ca-4163-ad7e-bbcdb1fdbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_split=12, n_jobs=-1, oob_score=True,\n",
       "                       random_state=0, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=12, n_jobs=-1, oob_score=True,\n",
       "                       random_state=0, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_split=12, n_jobs=-1, oob_score=True,\n",
       "                       random_state=0, verbose=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100,random_state=0,oob_score=True,min_samples_split=12,n_jobs=-1,verbose=True)\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# jobs=-1 => -1 will use all the hardware available on the sytem to build the tree, Verbose will print result for you on the screen\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9b017-a10d-4419-8c9e-296468e61ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion\n",
    "#These steps outline a complete workflow for a machine learning classification task, from data preparation to model evaluation.\n",
    "#This process involves critical stages such as understanding the dataset, preparing the data for modeling, choosing an appropriate model, training the model, \n",
    "#and evaluating its performance to ensure it can make accurate predictions on new, unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
